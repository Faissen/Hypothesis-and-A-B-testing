{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Faissen/Hypothesis-and-A-B-testing/blob/main/Hypothesis_testing_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI2sXc5HmCNn"
      },
      "source": [
        "# Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "l1FpJAacmCNn"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import numpy as np\n",
        "from scipy import stats as st"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7PeyqUT2mCNp",
        "outputId": "00476b47-faf8-4026-bc1f-2be4e0455d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/datasets/hypotheses_us.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2559593535.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Import the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/datasets/hypotheses_us.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Check the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datasets/hypotheses_us.csv'"
          ]
        }
      ],
      "source": [
        "#Import the data\n",
        "hypothesis = pd.read_csv('/datasets/hypotheses_us.csv', sep=';')\n",
        "print(hypothesis.head(), '\\n')\n",
        "\n",
        "# Check the data\n",
        "print(hypothesis.info(), '\\n')\n",
        "print(hypothesis.describe(), '\\n')\n",
        "print(f'Duplicated lines: ', hypothesis.duplicated().sum(), '\\n')\n",
        "print(f'Null-values by columns: ', '\\n', hypothesis.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbFTFILbmCNq"
      },
      "source": [
        "No null values, nor duplicated lines. Data types are correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEAkQwqImCNq"
      },
      "outputs": [],
      "source": [
        "# Snake_case\n",
        "new_columns_name = []\n",
        "for column_name in hypothesis.columns:\n",
        "    name_lowered = column_name.lower()\n",
        "    new_columns_name.append(name_lowered)\n",
        "\n",
        "hypothesis.columns = new_columns_name\n",
        "print(hypothesis.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS5IJUSdmCNq"
      },
      "source": [
        "# Part 1 - Prioritizing hypothesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZNIRjoWmCNr"
      },
      "source": [
        "## 1 - Classification following framework ICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsNLbJYomCNr"
      },
      "outputs": [],
      "source": [
        "# ICE = Impact x Confidence x Ease\n",
        "# ICE score = (Impact x Confidence) / Ease\n",
        "\n",
        "hypothesis['ice'] = round(((hypothesis['impact'] * hypothesis['confidence']) / hypothesis['effort']),1)\n",
        "hypothesis = hypothesis.sort_values(by='ice', ascending=False)\n",
        "hypothesis_ice = hypothesis[['hypothesis','ice']]\n",
        "print(hypothesis_ice)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjkMPGzQmCNr"
      },
      "source": [
        "## 2 - Classification following framework RICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3aArrTomCNr"
      },
      "outputs": [],
      "source": [
        "# RICE = Reach x Impact x Confidence x Ease\n",
        "# ICE score = (Reach x Impact x Confidence) / Ease\n",
        "\n",
        "hypothesis['rice'] = round(((hypothesis['reach'] * hypothesis['impact'] * hypothesis['confidence']) / hypothesis['effort']),1)\n",
        "hypothesis = hypothesis.sort_values(by='rice', ascending=False)\n",
        "hypothesis_rice = hypothesis[['hypothesis','rice']]\n",
        "print(hypothesis_rice)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_88LM8-tmCNs"
      },
      "source": [
        "## 3 - How does the classification change between ICE and RICE? Why does it happen?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53SSY4KDmCNs"
      },
      "source": [
        "The main difference between ICE and RICE is that RICE considers how many users will be impacted by the change.\n",
        "\n",
        "The main hypohesis from ICE are hypothesis 8, 0, 7 and 6.\n",
        "\n",
        "The main hypohesis from RICE are hypothesis 7, 2, 0 and 6.\n",
        "\n",
        "Hypothesis 0 and 7 appears in both analysis in the first four places."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTBksnnimCNs"
      },
      "outputs": [],
      "source": [
        "print(f'Hypothesis 0: ', hypothesis['hypothesis'][0], '\\n',f'Hypothesis 7: ', hypothesis['hypothesis'][7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udv2u00ymCNs"
      },
      "source": [
        "# Part 2 - A/B testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIGBaFtPmCNt"
      },
      "outputs": [],
      "source": [
        "#Import the data (optimized option)\n",
        "orders = pd.read_csv('/datasets/orders_us.csv', sep=',', dtype={'group':'category'} , parse_dates=['date'])\n",
        "print(orders.head(), '\\n')\n",
        "\n",
        "# Check the data\n",
        "print(orders.info(), '\\n')\n",
        "print(orders.describe(), '\\n')\n",
        "print(f'Duplicated lines: ', orders.duplicated().sum(), '\\n')\n",
        "print(f'Null-values by columns: ', '\\n', orders.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNpm3gIomCNt"
      },
      "source": [
        "No null values, nor duplicated lines. Data types are correct fter loading group and date with the most adequate data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlRMhghcmCNt"
      },
      "outputs": [],
      "source": [
        "# Snake_case\n",
        "def snake_columns(df):\n",
        "    df.columns = [\n",
        "        re.sub(r'(?<!_)Id$', '_id', col)  # adds _ prior to 'Id' at the end\n",
        "           .replace('Id', '_id')\n",
        "           .lower()\n",
        "        for col in df.columns\n",
        "    ]\n",
        "    return df\n",
        "\n",
        "snake_columns(orders)\n",
        "print(orders.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kp28LkFmCNt"
      },
      "outputs": [],
      "source": [
        "#Import the data (optimized option)\n",
        "visits = pd.read_csv('/datasets/visits_us.csv', sep=',', dtype={'group':'category'} , parse_dates=['date'])\n",
        "print(visits.head(), '\\n')\n",
        "\n",
        "# Check the data\n",
        "print(visits.info(), '\\n')\n",
        "print(visits.describe(), '\\n')\n",
        "print(f'Duplicated lines: ', visits.duplicated().sum(), '\\n')\n",
        "print(f'Null-values by columns: ', '\\n', visits.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiI3X8eImCNu"
      },
      "source": [
        "No null values, nor duplicated lines. Data types are correct fter loading group and date with the most adequate data types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDKSSliamCNu"
      },
      "source": [
        "## 1- Plot cumulated revenue by group. Take conclusions and build conjectures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrIe7h36mCNu"
      },
      "outputs": [],
      "source": [
        "revenue_by_group = orders.groupby('group')['revenue'].sum().reset_index()\n",
        "#print(revenue_by_group)\n",
        "\n",
        "plt.bar(revenue_by_group['group'], revenue_by_group['revenue'])\n",
        "plt.title('Total revenue by group')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Revenue')\n",
        "plt.show()\n",
        "\n",
        "revenue_rate = round(revenue_by_group[revenue_by_group['group']=='B']['revenue'].values[0] /\n",
        "                     revenue_by_group[revenue_by_group['group']=='A']['revenue'].values[0] ,1)\n",
        "\n",
        "print(f'Revenue of group B is {revenue_rate}x bigger than revenue of group A.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57-lXKtymCNu"
      },
      "source": [
        "Why is group B total revenue bigger than group A? Do both groups have the same size and the same time period?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfGGnBHnmCNv"
      },
      "source": [
        "## 2- Plot average cumulated revenue by group. Take conclusions and build conjectures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCbLCjzjmCNv"
      },
      "outputs": [],
      "source": [
        "revenue_by_group_and_date = orders.groupby(['date','group'])['revenue'].mean().reset_index()\n",
        "revenue_by_group_and_date.rename(columns={'revenue':'avg_revenue'}, inplace=True)\n",
        "print(revenue_by_group_and_date.head())\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=revenue_by_group_and_date, x='date',y='avg_revenue', hue='group')\n",
        "plt.title('Average cumulated revenue by group')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Average revenue')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m9-KptAmCNv"
      },
      "source": [
        "There are some atypical vales in both groups B, more visible in group B."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD8hJK7CmCNv"
      },
      "source": [
        "## 3- Plot the relative difference of the average cumulated revenue of group B regarding group A.  Take conclusions and build conjectures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI4GluGUmCNv"
      },
      "outputs": [],
      "source": [
        "cumulative_revenueA = revenue_by_group_and_date[revenue_by_group_and_date['group']=='A'].rename(columns={'avg_revenue':'avg_revenueA'}).drop(columns='group')\n",
        "cumulative_revenueB = revenue_by_group_and_date[revenue_by_group_and_date['group']=='B'].rename(columns={'avg_revenue':'avg_revenueB'}).drop(columns='group')\n",
        "cumulative_revenue_merged = cumulative_revenueA.merge(cumulative_revenueB, on='date', how='left')\n",
        "#print(cumulative_revenueA.head(), '\\n')\n",
        "#print(cumulative_revenueB.head(), '\\n')\n",
        "print(cumulative_revenue_merged.head(), '\\n')\n",
        "\n",
        "plt.plot(cumulative_revenue_merged['date'],(cumulative_revenue_merged['avg_revenueB'] / cumulative_revenue_merged['avg_revenueA'])-1)\n",
        "plt.axhline(y=0, color='grey',linestyle='--')\n",
        "plt.tight_layout()\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Average cumulated revenue by group')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Average cumulated revenue ratio (B/A -1)');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9NLgzklmCNw"
      },
      "source": [
        "Trends with some variability and inconsistencies. May be related to atypical values detected previouslly. Nevetheless, from 28.August group A average revenue started increasing compared with group B."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8M0D4ggmCNw"
      },
      "source": [
        "## 4- Calculate the conversion rate of each group as the ratio of orders to the number of visits for each day. Plot the daily conversion rates of the two groups and describe the difference. Draw conclusions and formulate hypotheses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s6qOs7tmCNw"
      },
      "outputs": [],
      "source": [
        "# Conversion rate = daily_orders / daily_visits\n",
        "daily_orders = orders.groupby('date')['transaction_id'].nunique().reset_index()\n",
        "print(daily_orders.head(),'\\n')\n",
        "\n",
        "daily_visits_by_group = visits.groupby(['date','group'])['visits'].sum().reset_index()\n",
        "print(daily_visits_by_group.head(),'\\n')\n",
        "\n",
        "daily_visits_by_group_merged = daily_visits_by_group.merge(daily_orders,on='date',how='left')\n",
        "#print(daily_visits_by_group_merged.head(),'\\n')\n",
        "\n",
        "daily_visits_by_group_merged['conversion_rate'] = round(daily_visits_by_group_merged['transaction_id'] / daily_visits_by_group_merged['visits'] *100,2)\n",
        "print(daily_visits_by_group_merged.head(),'\\n')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=daily_visits_by_group_merged, x='date',y='conversion_rate', hue='group')\n",
        "plt.title('Average cumulated revenue by group')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Conversion rate (%)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghwNkgB1mCNw"
      },
      "source": [
        "Conversion rate for both groups is very instable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crk_mqjzmCNw"
      },
      "source": [
        "## 5- Plot the relative difference in cumulative conversion for group B compared to group A. Draw conclusions and formulate hypotheses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iExnYDqumCNx"
      },
      "outputs": [],
      "source": [
        "cumulative_conversionA = daily_visits_by_group_merged[daily_visits_by_group_merged['group']=='A'].rename(\n",
        "    columns={'conversion_rate':'conversion_rateA'}).drop(columns=['group','visits','transaction_id'])\n",
        "cumulative_conversionB = daily_visits_by_group_merged[daily_visits_by_group_merged['group']=='B'].rename(\n",
        "    columns={'conversion_rate':'conversion_rateB'}).drop(columns=['group','visits','transaction_id'])\n",
        "cumulative_conversion_merged = cumulative_conversionA.merge(cumulative_conversionB, on='date', how='left')\n",
        "#print(cumulative_conversionA.head(), '\\n')\n",
        "#print(cumulative_conversionB.head(), '\\n')\n",
        "print(cumulative_conversion_merged.head(), '\\n')\n",
        "\n",
        "\n",
        "plt.plot(cumulative_conversion_merged['date'],\n",
        "         (cumulative_conversion_merged['conversion_rateB'] / cumulative_conversion_merged['conversion_rateA'])\n",
        "         -1)\n",
        "plt.axhline(y=0, color='grey',linestyle='--')\n",
        "plt.tight_layout()\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Average cumulated conversion rate by group')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Average cumulated conversion rate ratio (B/A -1)');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcEW6cN_mCNx"
      },
      "source": [
        "Trends with some variability. Group B started better,than conversion rate started being below group A. Crrently conversion rate of group B is improving."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFSroVRwmCNx"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b> Comentário do revisor: </b> <a class=\"tocSkip\"></a>\n",
        "\n",
        "- [x] A receita cumulativa por grupo foi analisada\n",
        "- [x] A diferença relativa do tamanho médio do pedido foi calculada\n",
        "- [x] A conversão por grupo foi analisada\n",
        "- [x] A conclusão foi apresentada\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FISmYCLhmCN9"
      },
      "source": [
        "## 6- Calculate the 95th and 99th percentiles for the number of orders per user. Define the point at which a data point becomes an anomaly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BdmULWimCN9"
      },
      "outputs": [],
      "source": [
        "#Number of orders by user\n",
        "orders_by_users = orders.groupby('visitor_id')['transaction_id'].nunique().reset_index().sort_values(by='transaction_id', ascending=True)\n",
        "print(orders_by_users.head(),'\\n')\n",
        "\n",
        "percentiles = np.percentile(orders_by_users['transaction_id'],[95,99])\n",
        "print(f'95% of users made {percentiles[0]} orders or less')\n",
        "print(f'99% of users made {percentiles[1]} orders or less', '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDGbV4NymCN9"
      },
      "source": [
        "More than 2 orders per user may be considered an anomaly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJkL3TfnmCN9"
      },
      "source": [
        "## 7- Create a scatter plot of the order prices. Draw conclusions and formulate hypotheses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8o8Crh9mCN9"
      },
      "outputs": [],
      "source": [
        "#Number of orders by user\n",
        "revenue_by_orders = orders.groupby('transaction_id')['revenue'].sum().reset_index()\n",
        "print(revenue_by_orders.head(),'\\n')\n",
        "\n",
        "x_values = pd.Series(range(0,len(revenue_by_orders['revenue'])))\n",
        "plt.scatter(revenue_by_orders['transaction_id'],revenue_by_orders['revenue'])\n",
        "plt.tight_layout()\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Revenue by orders')\n",
        "plt.ylabel('Revenue');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-lnqAHfmCN9"
      },
      "source": [
        "There are some atypical results that should be disregarded to obtain a more valid analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFyv_BtqmCN-"
      },
      "source": [
        "## 8- Calculate the 95th and 99th percentiles of the order prices. Define the point at which a data point becomes an anomaly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJ4EL_wtmCN-"
      },
      "outputs": [],
      "source": [
        "percentiles2 = np.percentile(revenue_by_orders['revenue'],[95,99])\n",
        "print(f'95% of orders is <= {percentiles2[0]}')\n",
        "print(f'99% of orders is <= {percentiles2[1]}', '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3b1qrr1mCN-"
      },
      "source": [
        "## 9- Find the statistical significance of the difference in conversion between the groups using the raw data. Draw conclusions and formulate hypotheses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydxW4V3RmCN-"
      },
      "outputs": [],
      "source": [
        "print(cumulative_conversion_merged.head(), '\\n')\n",
        "# Print p-value\n",
        "p_value = round(st.mannwhitneyu(cumulative_conversion_merged['conversion_rateA'], cumulative_conversion_merged['conversion_rateB'])[1],3)\n",
        "print(f'p-value is {p_value}')\n",
        "\n",
        "conversion_gain = cumulative_conversion_merged['conversion_rateB'].mean() / cumulative_conversion_merged['conversion_rateA'].mean() -1\n",
        "print(f'Conversion gain from group B to group A is {round(conversion_gain*100,1)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQhrlT6WmCN-"
      },
      "source": [
        "p-value is > 0.05 therefore we can not reject the null hypothesis. There is no statiscal significance regarding conversion between groups A and B."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGbNER4UmCN-"
      },
      "source": [
        "## 10- Find the statistical significance of the difference in average order size between the groups using the raw data. Draw conclusions and formulate hypotheses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGG-yTTJmCN_"
      },
      "outputs": [],
      "source": [
        "print(cumulative_revenue_merged.head(), '\\n')\n",
        "# Print p-value\n",
        "p_value = round(st.mannwhitneyu(cumulative_revenue_merged['avg_revenueA'], cumulative_revenue_merged['avg_revenueB'])[1],2)\n",
        "print(f'p-value is {p_value}')\n",
        "\n",
        "revenue_gain = cumulative_revenue_merged['avg_revenueB'].mean() / cumulative_revenue_merged['avg_revenueA'].mean() -1\n",
        "print(f'Revenue gain from group B to group A is {round(revenue_gain*100,1)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSv-N2uxmCN_"
      },
      "source": [
        "p-value is > 0.05 therefore we can not reject the null hypothesis. There is no statiscal significance in revenue change between groups A and B even though the difference is~24%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iE7BT_SmCN_"
      },
      "source": [
        "## 11- Find the statistical significance of the difference in conversion between the groups using the filtered data. Draw conclusions and formulate hypotheses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzKQBVp1mCN_"
      },
      "outputs": [],
      "source": [
        "# Filter data\n",
        "\n",
        "#95 and 99º percentile:\n",
        "# Orders: 2, 4\n",
        "# Revenue: 435.54, 900.90\n",
        "\n",
        "orders_visits = orders.merge(visits,on=['date','group'], how='left')\n",
        "#print(orders_visits.head())\n",
        "#print(orders_visits.info())\n",
        "orders_visits_filtered = orders_visits[\n",
        "    (orders_visits['revenue'] <= 500) &\n",
        "    (orders_visits.groupby('visitor_id')['transaction_id'].transform('count') < 4)\n",
        "]\n",
        "\n",
        "print(orders_visits_filtered.head())\n",
        "#print(orders_visits_filtered.info())\n",
        "\n",
        "# Conversion rate = daily_orders / daily_visits\n",
        "daily_orders_filtered = orders_visits_filtered.groupby('date')['transaction_id'].nunique().reset_index()\n",
        "print(daily_orders_filtered.head())\n",
        "\n",
        "daily_visits_by_group_filtered = orders_visits_filtered.groupby(['date','group'])['visits'].sum().reset_index()\n",
        "print(daily_visits_by_group_filtered.head(),'\\n')\n",
        "\n",
        "daily_visits_by_group_filtered_merged = daily_visits_by_group_filtered.merge(daily_orders_filtered,on='date',how='left')\n",
        "print(daily_visits_by_group_filtered_merged.head(),'\\n')\n",
        "\n",
        "daily_visits_by_group_filtered_merged['conversion_rate'] = round(daily_visits_by_group_filtered_merged['transaction_id'] /\n",
        "                                                                 daily_visits_by_group_filtered_merged ['visits'] *100,2)\n",
        "print(daily_visits_by_group_filtered_merged.head(),'\\n')\n",
        "\n",
        "\n",
        "cumulative_conversionA_filtered = daily_visits_by_group_filtered_merged[daily_visits_by_group_filtered_merged['group']=='A'].rename(\n",
        "    columns={'conversion_rate':'conversion_rateA'}).drop(columns=['group','visits','transaction_id'])\n",
        "cumulative_conversionB_filtered = daily_visits_by_group_filtered_merged[daily_visits_by_group_filtered_merged['group']=='B'].rename(\n",
        "    columns={'conversion_rate':'conversion_rateB'}).drop(columns=['group','visits','transaction_id'])\n",
        "cumulative_conversion_merged_filtered = cumulative_conversionA_filtered.merge(cumulative_conversionB_filtered, on='date', how='left')\n",
        "#print(cumulative_conversionA.head(), '\\n')\n",
        "#print(cumulative_conversionB.head(), '\\n')\n",
        "print(cumulative_conversion_merged_filtered.head(), '\\n')\n",
        "\n",
        "# Print p-value\n",
        "p_value_filtered = round(st.mannwhitneyu(cumulative_conversion_merged_filtered['conversion_rateA'],\n",
        "                                cumulative_conversion_merged_filtered['conversion_rateB'])[1],3)\n",
        "print(f'p-value is {p_value_filtered}')\n",
        "\n",
        "conversion_gain_filtered = (cumulative_conversion_merged_filtered['conversion_rateB'].mean() /\n",
        "                   cumulative_conversion_merged_filtered['conversion_rateA'].mean()) -1\n",
        "print(f'Conversion gain from group B to group A is {round(conversion_gain_filtered*100,1)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WHrqGmxmCOA"
      },
      "source": [
        "p-value is < 0.05 therefore we can reject the null hypothesis. There is statiscal significance regarding conversion between groups A and B.\n",
        "\n",
        "Group B presented significantly lower conversions than group A."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMFcDX7VmCOA"
      },
      "source": [
        "## 12- Find the statistical significance of the difference in average order size between the groups using the filtered data. Draw conclusions and formulate hypotheses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0TQ0ZKCmCOA"
      },
      "outputs": [],
      "source": [
        "print(orders_visits_filtered.head())\n",
        "revenue_by_group_and_date_filtered = orders_visits_filtered.groupby(['date','group'])['revenue'].mean().reset_index()\n",
        "revenue_by_group_and_date_filtered.rename(columns={'revenue':'avg_revenue'}, inplace=True)\n",
        "print(revenue_by_group_and_date.head())\n",
        "cumulative_revenueA_filtered = revenue_by_group_and_date_filtered[\n",
        "    revenue_by_group_and_date_filtered['group']=='A'].rename(columns={'avg_revenue':'avg_revenueA'}).drop(columns='group')\n",
        "cumulative_revenueB_filtered = revenue_by_group_and_date_filtered[\n",
        "    revenue_by_group_and_date_filtered['group']=='B'].rename(columns={'avg_revenue':'avg_revenueB'}).drop(columns='group')\n",
        "\n",
        "cumulative_revenue_merged_filtered = cumulative_revenueA_filtered.merge(cumulative_revenueB_filtered, on='date', how='left')\n",
        "print(cumulative_revenueA_filtered.head(), '\\n')\n",
        "print(cumulative_revenueB_filtered.head(), '\\n')\n",
        "print(cumulative_revenue_merged_filtered.head(), '\\n')\n",
        "\n",
        "# Print p-value\n",
        "p_value_filt = round(st.mannwhitneyu(cumulative_revenue_merged_filtered['avg_revenueA'], cumulative_revenue_merged_filtered['avg_revenueB'])[1],2)\n",
        "print(f'p-value is {p_value_filt}')\n",
        "\n",
        "revenue_gain_filt = cumulative_revenue_merged_filtered['avg_revenueB'].mean() / cumulative_revenue_merged_filtered['avg_revenueA'].mean() -1\n",
        "print(f'Revenue gain from group B to group A is {round(revenue_gain_filt*100,1)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKAwz9fxmCOA"
      },
      "source": [
        "p-value is > 0.05 therefore we can not reject the null hypothesis. There is no statiscal significance in revenue change between groups A and B which makes sense since the difference is less than 2%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUUyaaVTmCOA"
      },
      "source": [
        "## 13- Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if6xKEXsmCOA"
      },
      "source": [
        "Based on tests results after removing abnormal users:\n",
        "* Conversion - There is statiscal significance regarding conversion between groups A and B. Group B presented significantly lower (~17%) conversions than group A.\n",
        "* Average revenue - There is no statiscal significance in revenue change between groups A and B which makes sense since the difference is less than 2%.\n",
        "\n",
        "We can terminate the test considering group A as leader."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}